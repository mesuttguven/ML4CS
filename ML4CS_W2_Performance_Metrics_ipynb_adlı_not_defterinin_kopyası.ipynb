{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML4CS_W2_Performance_Metrics.ipynb adlı not defterinin kopyası",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mesuttguven/ML4CS/blob/main/ML4CS_W2_Performance_Metrics_ipynb_adl%C4%B1_not_defterinin_kopyas%C4%B1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below shows how to gather Confusion Matrix and performance metrics;\n",
        "2 sets are provided, respectively: y_pred for MODEL's prediction and y_true for the GROUND TRUTH labels. "
      ],
      "metadata": {
        "id": "zMElwIuW4ZPT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOGyPZNE39sn",
        "outputId": "c2b400fd-e99a-422b-ecc5-a35ba9407873"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACCURACY: 0.8\n",
            "RECALL: 0.8333333333333333\n",
            "\n",
            "CONFUSION MATRIX:\n",
            " [[2 0]\n",
            " [1 2]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "y_true = [0, 0, 1, 1, 1]\n",
        "y_pred = [0, 0, 0, 1, 1]\n",
        "\n",
        "print('ACCURACY:', accuracy_score(y_true, y_pred))\n",
        "print('RECALL:', recall_score(y_true, y_pred, average='macro'))\n",
        "print('\\nCONFUSION MATRIX:\\n', confusion_matrix(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "y_true = [0, 1, 2, 2, 2]\n",
        "y_pred = [0, 0, 2, 2, 1]\n",
        "target_names = ['class 0', 'class 1', 'class 2']\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uamVT5j_4VyB",
        "outputId": "03b6eff0-ba8e-40dc-f070-a7a643a6fe23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.50      1.00      0.67         1\n",
            "     class 1       0.00      0.00      0.00         1\n",
            "     class 2       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.60         5\n",
            "   macro avg       0.50      0.56      0.49         5\n",
            "weighted avg       0.70      0.60      0.61         5\n",
            "\n"
          ]
        }
      ]
    }
  ]
}